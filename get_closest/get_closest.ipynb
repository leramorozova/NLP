{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sklearn.metrics import classification_report\n",
    "import textdistance\n",
    "from string import punctuation\n",
    "from tqdm import tqdm\n",
    "punct = set(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad = open('sents_with_mistakes.txt', encoding='utf8').read().splitlines()\n",
    "true = open('correct_sents.txt', encoding='utf8').read().splitlines()\n",
    "\n",
    "corpus = [sent.split() for sent in open('corpus_ng.txt', encoding='utf8').read().splitlines()]\n",
    "WORDS = Counter()\n",
    "for sent in corpus:\n",
    "    WORDS.update(sent)\n",
    "    \n",
    "vocab = list(WORDS.keys())\n",
    "id2word = {i:word for i, word in enumerate(vocab)}\n",
    "\n",
    "vec = TfidfVectorizer(analyzer='char', ngram_range=(1,1))\n",
    "X = vec.fit_transform(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_words(sent_1, sent_2):\n",
    "    tokens_1 = sent_1.lower().split()\n",
    "    tokens_2 = sent_2.lower().split()\n",
    "    \n",
    "    tokens_1 = [re.sub('(^\\W+|\\W+$)', '', token) for token in tokens_1 if (set(token)-punct)]\n",
    "    tokens_2 = [re.sub('(^\\W+|\\W+$)', '', token) for token in tokens_2 if (set(token)-punct)]\n",
    "    \n",
    "    return list(zip(tokens_1, tokens_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала отбираем 3 ближайших по косинусному расстроянию слов, затем из них выбираем ближайшее по левинштейну."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_hybrid_match(text, X, vec):\n",
    "    v = vec.transform([text])\n",
    "    similarities = cosine_distances(v, X)\n",
    "    topn = similarities.argsort()[0][:3]\n",
    "    lookup = [id2word[top] for top in topn]\n",
    "    similarities = Counter()\n",
    "    for word in lookup:\n",
    "        similarities[word] = textdistance.levenshtein.normalized_similarity(text, word)\n",
    "    closest = 0\n",
    "    return similarities.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работает очень даже быстро:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36 ms, sys: 0 ns, total: 36 ms\n",
      "Wall time: 36.2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'апофеоз'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_closest_hybrid_match('апофеоз',  X, vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 916/916 [04:21<00:00,  3.10it/s]\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for i in tqdm(range(len(true))):\n",
    "    word_pairs = align_words(true[i], bad[i])\n",
    "    pairs_predict = []\n",
    "    for pair in word_pairs:\n",
    "        pairs_predict.append([pair[0], get_closest_hybrid_match(pair[1],  X, vec)])\n",
    "    for pair in pairs_predict:\n",
    "        y_true.append(1)\n",
    "        if pair[0] == pair[1]:\n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.79      0.89     10012\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     10012\n",
      "   macro avg       0.50      0.40      0.44     10012\n",
      "weighted avg       1.00      0.79      0.89     10012\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество где-то хромает, посмотрим на ошибки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 916/916 [05:04<00:00,  2.64it/s]\n"
     ]
    }
   ],
   "source": [
    "df_dict = {'true':[], 'bad':[], 'correction':[]}\n",
    "\n",
    "for i in tqdm(range(len(true))):\n",
    "    word_pairs = align_words(true[i], bad[i])\n",
    "    for pair in word_pairs:\n",
    "        if pair[0] != get_closest_hybrid_match(pair[1],  X, vec):\n",
    "            df_dict['true'].append(pair[0])\n",
    "            df_dict['bad'].append(pair[1])\n",
    "            df_dict['correction'].append(get_closest_hybrid_match(pair[1],  X, vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>bad</th>\n",
       "      <th>correction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>симпатичнейшее</td>\n",
       "      <td>симпатичнейшое</td>\n",
       "      <td>пластичнейшими</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>шпионское</td>\n",
       "      <td>шпионское</td>\n",
       "      <td>шпионские</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>гламурный</td>\n",
       "      <td>гламурный</td>\n",
       "      <td>гуманный</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>бонда</td>\n",
       "      <td>бонда</td>\n",
       "      <td>банд</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>superheadz</td>\n",
       "      <td>superheadz</td>\n",
       "      <td>herederas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>clap</td>\n",
       "      <td>clap</td>\n",
       "      <td>place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>camera</td>\n",
       "      <td>camera</td>\n",
       "      <td>america</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>получатся</td>\n",
       "      <td>полчатся</td>\n",
       "      <td>ополчатся</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>язычки</td>\n",
       "      <td>язычки</td>\n",
       "      <td>язычка</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>все</td>\n",
       "      <td>все</td>\n",
       "      <td>есв</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>очень</td>\n",
       "      <td>оччччень</td>\n",
       "      <td>чечни</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>милые</td>\n",
       "      <td>милые</td>\n",
       "      <td>милы</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>насчет</td>\n",
       "      <td>нащщот</td>\n",
       "      <td>защищено</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>чавеса</td>\n",
       "      <td>чавеса</td>\n",
       "      <td>чавес</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>на</td>\n",
       "      <td>на</td>\n",
       "      <td>анан</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>попавшим</td>\n",
       "      <td>попавшим</td>\n",
       "      <td>пропавшим</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>аварийно-спасательных</td>\n",
       "      <td>аварийно-спасательных</td>\n",
       "      <td>аварийно-восстановительных</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>напрасно</td>\n",
       "      <td>нарасно</td>\n",
       "      <td>роснано</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>на</td>\n",
       "      <td>на</td>\n",
       "      <td>анан</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>в</td>\n",
       "      <td>вобщем</td>\n",
       "      <td>общем</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     true                    bad                  correction\n",
       "0          симпатичнейшее         симпатичнейшое              пластичнейшими\n",
       "1               шпионское              шпионское                   шпионские\n",
       "2               гламурный              гламурный                    гуманный\n",
       "3                   бонда                  бонда                        банд\n",
       "4              superheadz             superheadz                   herederas\n",
       "5                    clap                   clap                       place\n",
       "6                  camera                 camera                     america\n",
       "7               получатся               полчатся                   ополчатся\n",
       "8                  язычки                 язычки                      язычка\n",
       "9                     все                    все                         есв\n",
       "10                  очень               оччччень                       чечни\n",
       "11                  милые                  милые                        милы\n",
       "12                 насчет                 нащщот                    защищено\n",
       "13                 чавеса                 чавеса                       чавес\n",
       "14                     на                     на                        анан\n",
       "15               попавшим               попавшим                   пропавшим\n",
       "16  аварийно-спасательных  аварийно-спасательных  аварийно-восстановительных\n",
       "17               напрасно                нарасно                     роснано\n",
       "18                     на                     на                        анан\n",
       "19                      в                 вобщем                       общем"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(df_dict)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблема в том, что, видимо, векторно блишайшее слово и эталон без опечатки иногда не совпадают, поэтому алгоритм исправляет то, не стоило бы. Качество можно улучшить, добавив подкрепление корпусом - если слово до исправления в нем есть, значит, скорее всего, это слово без опечатки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1664313\n"
     ]
    }
   ],
   "source": [
    "grand_corpus = []\n",
    "for i in range(len(corpus)):\n",
    "    for word in corpus[i]:\n",
    "        grand_corpus.append(word)\n",
    "print(len(grand_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 916/916 [01:55<00:00,  7.92it/s]\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for i in tqdm(range(len(true))):\n",
    "    word_pairs = align_words(true[i], bad[i])\n",
    "    pairs_predict = []\n",
    "    for pair in word_pairs:\n",
    "        if pair[1] not in grand_corpus:\n",
    "            pairs_predict.append([pair[0], get_closest_hybrid_match(pair[1],  X, vec)])\n",
    "        else:\n",
    "            pairs_predict.append([pair[0], pair[1]])\n",
    "    for pair in pairs_predict:\n",
    "        y_true.append(1)\n",
    "        if pair[0] == pair[1]:\n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.83      0.90     10012\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     10012\n",
      "   macro avg       0.50      0.41      0.45     10012\n",
      "weighted avg       1.00      0.83      0.90     10012\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество улучшилось (хотя и не ахти, я думаю, из-за того, что корпус маловат), и работaет это более чем в полтора раза быстрее."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
