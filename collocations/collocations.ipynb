{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проанализируем текст с помощью udpipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading UDPipe model: done.\n"
     ]
    }
   ],
   "source": [
    "! ./udpipe --input horizontal --output conllu --tokenize --tag --parse russian-syntagrus-ud-2.4-190531.udpipe < testset2.txt > parsed.conllu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conllu import parse\n",
    "\n",
    "with open(\"parsed.conllu\", \"r\") as fd:\n",
    "    parsed_text = fd.read()\n",
    "    \n",
    "conllu_text = parse(parsed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('id', 2),\n",
       "             ('form', 'Я'),\n",
       "             ('lemma', 'я'),\n",
       "             ('upostag', 'PRON'),\n",
       "             ('xpostag', None),\n",
       "             ('feats',\n",
       "              OrderedDict([('Case', 'Nom'),\n",
       "                           ('Number', 'Sing'),\n",
       "                           ('Person', '1')])),\n",
       "             ('head', 3),\n",
       "             ('deprel', 'nsubj'),\n",
       "             ('deps', None),\n",
       "             ('misc', None)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conllu_text[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Составим частотный список глаголов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_verbs = {}\n",
    "\n",
    "for sentence in conllu_text:\n",
    "    for word in sentence:\n",
    "        if word[\"upostag\"] == \"VERB\":\n",
    "            if word[\"lemma\"] not in freq_verbs:\n",
    "                freq_verbs[word[\"lemma\"]] = 0 \n",
    "            else:\n",
    "                freq_verbs[word[\"lemma\"]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in list(freq_verbs):\n",
    "    if freq_verbs[key] < 51:\n",
    "        freq_verbs.pop(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'заявить': 257,\n",
       " 'подать': 273,\n",
       " 'просить': 143,\n",
       " 'признать': 344,\n",
       " 'стать': 212,\n",
       " 'сообщить': 216,\n",
       " 'обратиться': 138,\n",
       " 'отказаться': 116,\n",
       " 'рассматривать': 98,\n",
       " 'рассказать': 53,\n",
       " 'рассмотреть': 89,\n",
       " 'мочь': 348,\n",
       " 'начаться': 73,\n",
       " 'обвинить': 460,\n",
       " 'решить': 85,\n",
       " 'пытаться': 88,\n",
       " 'использовать': 56,\n",
       " 'напомнить': 96,\n",
       " 'получить': 126,\n",
       " 'передать': 67,\n",
       " 'направить': 104,\n",
       " 'удаться': 60,\n",
       " 'сказать': 97,\n",
       " 'иметь': 93,\n",
       " 'делать': 76,\n",
       " 'обжаловать': 101,\n",
       " 'отказать': 58,\n",
       " 'говорить': 138,\n",
       " 'счесть': 54,\n",
       " 'быть': 135,\n",
       " 'оставить': 60,\n",
       " 'дать': 69,\n",
       " 'удовлетворить': 172,\n",
       " 'вынести': 152,\n",
       " 'требовать': 172,\n",
       " 'являться': 112,\n",
       " 'обвинять': 119,\n",
       " 'принять': 150,\n",
       " 'выплатить': 61,\n",
       " 'назначить': 62,\n",
       " 'постановить': 56,\n",
       " 'обязать': 59,\n",
       " 'принадлежать': 53,\n",
       " 'подтвердить': 90,\n",
       " 'находиться': 116,\n",
       " 'арестовывать': 81,\n",
       " 'доказать': 56,\n",
       " 'предъявить': 96,\n",
       " 'пояснить': 57,\n",
       " 'согласиться': 61,\n",
       " 'взыскать': 62,\n",
       " 'отклонить': 68,\n",
       " 'провести': 62,\n",
       " 'приговорить': 122,\n",
       " 'запретить': 55,\n",
       " 'считать': 151,\n",
       " 'оспаривать': 53,\n",
       " 'нет': 67,\n",
       " 'утверждать': 70,\n",
       " 'связать': 56,\n",
       " 'оспорить': 67,\n",
       " 'объявить': 71,\n",
       " 'оказаться': 61,\n",
       " 'отменить': 82}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_verbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберем коллокации глагол + прямое дополнение. Я выбираю только ближайшего к глаголу соседа, поэтому мои коллокации несовершенны (в них могут попадать глагол + прилагательное в аккузативе), но я забила. Для существительного я не брала лемму, чтобы сохранить падежную связность с глаголом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "collocations = []\n",
    "\n",
    "def conditions(word, next_word):\n",
    "    cond = [\n",
    "        next_word,\n",
    "        word[\"upostag\"] == \"VERB\",\n",
    "        word[\"lemma\"] in freq_verbs,\n",
    "        next_word[\"feats\"] and \"Case\" in next_word[\"feats\"] and next_word[\"feats\"][\"Case\"] == \"Acc\"\n",
    "    ]\n",
    "    return all(cond)\n",
    "\n",
    "for sentence in conllu_text:\n",
    "    for i, word in enumerate(sentence):\n",
    "        if i < len(sentence) - 1 and conditions(word, sentence[i + 1]):\n",
    "            collocations.append([word[\"lemma\"], sentence[i + 1][\"form\"]])\n",
    "        elif i < len(sentence) - 1 and conditions(sentence[i + 1], word):\n",
    "            collocations.append([sentence[i + 1][\"lemma\"], word[\"form\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['рассмотреть', 'вопрос'],\n",
       " ['начаться', 'понедельник'],\n",
       " ['обвинить', 'лубянское'],\n",
       " ['получить', 'сроки'],\n",
       " ['обвинить', 'олигарха'],\n",
       " ['обвинить', 'Юлию'],\n",
       " ['просить', 'суд'],\n",
       " ['рассматривать', 'ходатайство'],\n",
       " ['делать', 'вынужденный'],\n",
       " ['иметь', 'вид']]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(collocations))\n",
    "collocations[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем log-likelihood, dice, PMI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.collocations import *\n",
    "\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_documents(collocations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('нет', 'судебного'),\n",
       " ('связать', 'подзащитного'),\n",
       " ('отказаться', 'Тегеран'),\n",
       " ('отказаться', 'Чечню'),\n",
       " ('сказать', 'Усачева'),\n",
       " ('сказать', 'что-то'),\n",
       " ('постановить', 'присяжные'),\n",
       " ('пояснить', 'суть'),\n",
       " ('говорить', 'друга'),\n",
       " ('говорить', 'что')]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmi = finder.nbest(bigram_measures.pmi, 100)\n",
    "pmi[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('просить', 'суд'),\n",
       " ('подать', 'иск'),\n",
       " ('принять', 'решение'),\n",
       " ('удовлетворить', 'иск'),\n",
       " ('удовлетворить', 'ходатайство'),\n",
       " ('вынести', 'решение'),\n",
       " ('обжаловать', 'решение'),\n",
       " ('иметь', 'право'),\n",
       " ('вынести', 'приговор'),\n",
       " ('обвинить', 'его')]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = finder.nbest(bigram_measures.likelihood_ratio, 100)\n",
    "lr[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('отказаться', 'Тегеран'),\n",
       " ('отказаться', 'Чечню'),\n",
       " ('сказать', 'Усачева'),\n",
       " ('сказать', 'что-то'),\n",
       " ('просить', 'суд'),\n",
       " ('говорить', 'друга'),\n",
       " ('говорить', 'что'),\n",
       " ('заявить', 'отвод'),\n",
       " ('находиться', 'время'),\n",
       " ('постановить', 'присяжные')]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = finder.score_ngrams(bigram_measures.dice)\n",
    "dice = sorted([x for x in scores if x[1] != 1.0], key=lambda x: x[1], reverse=True)[:100]\n",
    "dice = [x[0] for x in dice]\n",
    "dice[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдем пересечение всех топов-100:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('взыскать', 'недостающую'),\n",
       " ('доказать', 'невиновность'),\n",
       " ('запретить', 'деятельность'),\n",
       " ('заявить', 'отвод'),\n",
       " ('заявить', 'целый'),\n",
       " ('мочь', 'список'),\n",
       " ('находиться', 'время'),\n",
       " ('объявить', 'перерыв'),\n",
       " ('объявить', 'предпринимателя'),\n",
       " ('принадлежать', 'МИАНу'),\n",
       " ('принадлежать', 'ЮКОСу'),\n",
       " ('решить', 'проблему'),\n",
       " ('сообщить', 'ответ'),\n",
       " ('счесть', 'Касьянова'),\n",
       " ('счесть', 'доводы')}"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union = set(dice) & set(lr) & set(pmi)\n",
    "union"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним со словарем глагольной сочетаемости:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"verb_coll.txt\", \"r\") as fd:\n",
    "    dict_text = fd.read().split(\"\\n\")\n",
    "    \n",
    "dict_collocations1 = [(token.split()[-2], token.split()[-1]) for token in dict_text if len(token.split()) > 2]\n",
    "dict_collocations2 = [(token.split()[-1], token.split()[-2]) for token in dict_text if len(token.split()) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('решить', 'проблему')}"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_union = union & set(dict_collocations1) & set(dict_collocations2)\n",
    "new_union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось негусто. Полагаю, что это из-за моей халатности c поиском коллокаций. Я считаю, что в этот список почем зря не внесены следущие пары слов:\n",
    "\n",
    "объявить перерыв\n",
    "\n",
    "сообщить ответ\n",
    "\n",
    "запретить деятельность\n",
    "\n",
    "доказать невиновность\n",
    "\n",
    "Я считаю их коллокациями, так как для перечисленных глаголов их существительные являются единственными внутренними аргументами (что не верено, например, для пары слов \"счесть Касьянова\" - тут явно не хватает еще одного аргумента в инструменталисе) и они семантически связаны в том числе и как устойчивые выражения. Наример, нормально - \"объявить перерыв\", а \"сказать перерыв\" - невозможно. Добавим их в объединение вручную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('доказать', 'невиновность'),\n",
       " ('запретить', 'деятельность'),\n",
       " ('объявить', 'перерыв'),\n",
       " ('решить', 'проблему'),\n",
       " ('сообщить', 'ответ')}"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ultimate_union = new_union | {(\"объявить\", \"перерыв\"), (\"сообщить\", \"ответ\"),\n",
    "                              (\"запретить\", \"деятельность\"), (\"доказать\", \"невиновность\")}\n",
    "ultimate_union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не очень понимаю, как отранжировать эти коллокации руками, но допустим, что я буду считать коллокации тем более \"коллокативной\", чем более устойчивое выражение оно составляет (нельзя подставить другой глагол, например)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.6, pvalue=0.28475697986529375)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "ranged_collocations = [['объявить', 'перерыв'],\n",
    "                       ['доказать', 'невиновность'],\n",
    "                       ['решить', 'проблему'],\n",
    "                       ['запретить', 'деятельность'],\n",
    "                       ['сообщить', 'ответ']]\n",
    "\n",
    "stats.spearmanr(ranged_collocations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('доказать', 'невиновность'), 1.0), (('запретить', 'деятельность'), 1.0), (('объявить', 'перерыв'), 1.0), (('решить', 'проблему'), 1.0), (('сообщить', 'ответ'), 1.0)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('доказать', 'невиновность'),\n",
       " ('запретить', 'деятельность'),\n",
       " ('объявить', 'перерыв'),\n",
       " ('решить', 'проблему'),\n",
       " ('сообщить', 'ответ')]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = finder2.score_ngrams(bigram_measures.dice)\n",
    "print(scores)\n",
    "dice = [x[0] for x in scores]\n",
    "print(stats.spearmanr(dice))\n",
    "dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.6, pvalue=0.28475697986529375)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('доказать', 'невиновность'),\n",
       " ('запретить', 'деятельность'),\n",
       " ('объявить', 'перерыв'),\n",
       " ('решить', 'проблему'),\n",
       " ('сообщить', 'ответ')]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = finder2.nbest(bigram_measures.likelihood_ratio, 5)\n",
    "print(stats.spearmanr(lr))\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.6, pvalue=0.28475697986529375)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('доказать', 'невиновность'),\n",
       " ('запретить', 'деятельность'),\n",
       " ('объявить', 'перерыв'),\n",
       " ('решить', 'проблему'),\n",
       " ('сообщить', 'ответ')]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder2 = BigramCollocationFinder.from_documents(ranged_collocations)\n",
    "pmi = finder2.nbest(bigram_measures.pmi, 5)\n",
    "print(stats.spearmanr(pmi))\n",
    "pmi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
