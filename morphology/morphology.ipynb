{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестирование TreeTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если TreeTagger не установлен, прогоните следующую ячейку (скрипт установки в папке с заданием):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sh get_treetagger.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\treading parameters ...\n",
      "\ttagging ...\n",
      "Я\tP-1-snn\tя\n",
      "хочу\tVmip1s-a-e\tхотеть\n",
      "съесть\tVmn----a-p\tсъесть\n",
      "яблоко\tNcnsan\tяблоко\n",
      "!\tSENT\t!\n",
      "\t finished.\n"
     ]
    }
   ],
   "source": [
    "!echo 'Я хочу съесть яблоко!' | cmd/tree-tagger-russian "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Копипаста из семинара: открываю файл и обрабатываю тексты по инструкции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "from collections import defaultdict\n",
    "\n",
    "open_corpora = etree.fromstring(open('annot.opcorpora.no_ambig_strict.xml', 'rb').read())\n",
    "\n",
    "corpus = open('corpus_train.txt', 'w')\n",
    "vocab = defaultdict(set)\n",
    "tags = set()\n",
    "\n",
    "for sentence in open_corpora.xpath('//tokens'):\n",
    "    length = len(sentence.xpath('token'))\n",
    "    ended = False\n",
    "    for i,token in enumerate(sentence.xpath('token')):\n",
    "        word = token.xpath('@text')\n",
    "        gram_info = token.xpath('tfr/v/l/g/@v')\n",
    "        \n",
    "        if (i+1)==length and gram_info[0] == 'PNCT':\n",
    "            gram_info = ['SENT']\n",
    "            ended = True\n",
    "        \n",
    "            \n",
    "        corpus.write(word[0] + '\\t' + ','.join(gram_info) + '\\n')\n",
    "        lemma = token.xpath('tfr/v/l/@t')[0]\n",
    "        vocab[word[0].lower()].add((','.join(gram_info), lemma.lower()))\n",
    "        tags.add(','.join(gram_info))\n",
    "    \n",
    "    if not ended:\n",
    "        corpus.write('.\\tSENT\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('lexicon.txt', 'w')\n",
    "\n",
    "for word in vocab:\n",
    "    f.write(word + '\\t')\n",
    "    f.write('\\t'.join([' '.join(pair) for pair in vocab[word]]))\n",
    "    f.write('\\n')\n",
    "# f.write('SENT\\tSENT .')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('open_class.txt', 'w')\n",
    "\n",
    "f.write('\\n'.join([tag for tag in tags if 'NOUN' in tag or 'VERB' in tag or 'ADJF' in tag]))\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
