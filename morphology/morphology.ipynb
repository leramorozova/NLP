{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестирование TreeTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если TreeTagger не установлен, прогоните следующую ячейку (скрипт установки в папке с заданием):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sh get_treetagger.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\treading parameters ...\n",
      "\ttagging ...\n",
      "Я\tP-1-snn\tя\n",
      "хочу\tVmip1s-a-e\tхотеть\n",
      "съесть\tVmn----a-p\tсъесть\n",
      "яблоко\tNcnsan\tяблоко\n",
      "!\tSENT\t!\n",
      "\t finished.\n"
     ]
    }
   ],
   "source": [
    "!echo 'Я хочу съесть яблоко!' | cmd/tree-tagger-russian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "open_corpora = etree.fromstring(open('annot.opcorpora.no_ambig_strict.xml', 'rb').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итого у нас 10590 предложений. В таком случае разделим выборку на 10 частей: в каждой итерации будет 1059 примеров на тестовой выборке и 9531 предложение в тренировочной. Создадим массив кортежей (форматированое предложение для обучение, стандартное предложение для теста)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10590\n",
      "('«\\tPNCT\\nШкола\\tNOUN,inan,femn,sing,nomn\\nзлословия\\tNOUN,inan,neut,sing,gent\\n»\\tPNCT\\nучит\\tVERB,impf,tran,sing,3per,pres,indc\\nприкусить\\tINFN,perf,tran\\nязык\\tNOUN,inan,masc,sing,accs\\n', '« Школа злословия » учит прикусить язык')\n",
      "('Сохранится\\tVERB,perf,intr,sing,3per,futr,indc\\nли\\tPRCL\\nградус\\tNOUN,inan,masc,sing,nomn\\nдискуссии\\tNOUN,inan,femn,sing,gent\\nв\\tPREP\\nновом\\tADJF,Qual,masc,sing,loct\\nсезоне\\tNOUN,inan,masc,sing,loct\\n?\\tSENT\\n', 'Сохранится ли градус дискуссии в новом сезоне ?')\n"
     ]
    }
   ],
   "source": [
    "vocab = defaultdict(set)\n",
    "tags = set()\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for sentence in open_corpora.xpath('//tokens'):\n",
    "    formatted_sent = \"\"\n",
    "    standart_sent = []\n",
    "    length = len(sentence.xpath('token'))\n",
    "    for i,token in enumerate(sentence.xpath('token')):\n",
    "        word = token.xpath('@text')\n",
    "        gram_info = token.xpath('tfr/v/l/g/@v')\n",
    "        if (i + 1) == length and gram_info[0] == 'PNCT':\n",
    "            gram_info = ['SENT']\n",
    "            ended = True\n",
    "        formatted_sent += word[0] + '\\t' + ','.join(gram_info) + '\\n'\n",
    "        standart_sent.append(word[0])\n",
    "        lemma = token.xpath('tfr/v/l/@t')[0]\n",
    "        vocab[word[0].lower()].add((','.join(gram_info), lemma.lower()))\n",
    "        tags.add(','.join(gram_info))\n",
    "    if not ended:\n",
    "        formatted_sent += '.\\tSENT\\n'\n",
    "    standart_sent = \" \".join(standart_sent)\n",
    "    corpus.append((formatted_sent, standart_sent))\n",
    "\n",
    "print(len(corpus))\n",
    "for i in range(2):\n",
    "    print(corpus[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('lexicon.txt', 'w')\n",
    "\n",
    "for word in vocab:\n",
    "    f.write(word + '\\t')\n",
    "    f.write('\\t'.join([' '.join(pair) for pair in vocab[word]]))\n",
    "    f.write('\\n')\n",
    "f.close()\n",
    "\n",
    "f = open('open_class.txt', 'w')\n",
    "\n",
    "f.write('\\n'.join([tag for tag in tags if 'NOUN' in tag or 'VERB' in tag or 'ADJF' in tag]))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "cross_val_folds = []\n",
    "\n",
    "fold = []\n",
    "\n",
    "for i in range(len(corpus)):\n",
    "    fold.append(corpus[i])\n",
    "    if i % (len(corpus) / 10) == 0:\n",
    "        cross_val_folds.append(fold)\n",
    "        fold = []\n",
    "        \n",
    "print(len(cross_val_folds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train-tree-tagger -cl 2 -dtg 0.50 -sw 1.00 -ecw 0.15 -atg 1.20 lexicon.txt open_class.txt corpus_train.txt model_oc\n",
      "\n",
      "\treading the lexicon ...\n",
      "\t\treading the tagset ...\n",
      "\t\treading the lemmas ...\n",
      "\t\treading the entries ...\n",
      "\t\tsorting the lexicon ...\n",
      "\t\treading the open class tags ...\n",
      "\tcalculating tag frequencies ...\n",
      "51000\tmaking affix tree ...\n",
      "prefix lexicon: 807 nodes\n",
      "suffix lexicon: 1796 nodes\n",
      "\treading classes ...\n",
      "\tmaking ngram table ...\n",
      "63639\t33659\n",
      "finished.\n",
      "\tmaking decision tree ...\n",
      "84\tsaving parameters ...\n",
      "\n",
      "Number of nodes: 85\n",
      "Max. path length: 14\n",
      "\n",
      "done.\n",
      "\treading parameters ...\n",
      "\ttagging ...\n",
      "\t finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 1/10 [00:04<00:38,  4.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train-tree-tagger -cl 2 -dtg 0.50 -sw 1.00 -ecw 0.15 -atg 1.20 lexicon.txt open_class.txt corpus_train.txt model_oc\n",
      "\n",
      "\treading the lexicon ...\n",
      "\t\treading the tagset ...\n",
      "\t\treading the lemmas ...\n",
      "\t\treading the entries ...\n",
      "\t\tsorting the lexicon ...\n",
      "\t\treading the open class tags ...\n",
      "\tcalculating tag frequencies ...\n",
      "44000\tmaking affix tree ...\n",
      "prefix lexicon: 807 nodes\n",
      "suffix lexicon: 1799 nodes\n",
      "\treading classes ...\n",
      "\tmaking ngram table ...\n",
      "55150\t30018\n",
      "finished.\n",
      "\tmaking decision tree ...\n",
      "80\tsaving parameters ...\n",
      "\n",
      "Number of nodes: 81\n",
      "Max. path length: 15\n",
      "\n",
      "done.\n",
      "\treading parameters ...\n",
      "\ttagging ...\n",
      "7000\t finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 2/10 [00:08<00:34,  4.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train-tree-tagger -cl 2 -dtg 0.50 -sw 1.00 -ecw 0.15 -atg 1.20 lexicon.txt open_class.txt corpus_train.txt model_oc\n",
      "\n",
      "\treading the lexicon ...\n",
      "\t\treading the tagset ...\n",
      "\t\treading the lemmas ...\n",
      "\t\treading the entries ...\n",
      "\t\tsorting the lexicon ...\n",
      "\t\treading the open class tags ...\n",
      "\tcalculating tag frequencies ...\n",
      "44000\tmaking affix tree ...\n",
      "prefix lexicon: 807 nodes\n",
      "suffix lexicon: 1796 nodes\n",
      "\treading classes ...\n",
      "\tmaking ngram table ...\n",
      "55786\t30143\n",
      "finished.\n",
      "\tmaking decision tree ...\n",
      "82\tsaving parameters ...\n",
      "\n",
      "Number of nodes: 83\n",
      "Max. path length: 16\n",
      "\n",
      "done.\n",
      "\treading parameters ...\n",
      "\ttagging ...\n",
      "7000\t finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 3/10 [00:12<00:29,  4.27s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train-tree-tagger -cl 2 -dtg 0.50 -sw 1.00 -ecw 0.15 -atg 1.20 lexicon.txt open_class.txt corpus_train.txt model_oc\n",
      "\n",
      "\treading the lexicon ...\n",
      "\t\treading the tagset ...\n",
      "\t\treading the lemmas ...\n",
      "\t\treading the entries ...\n",
      "\t\tsorting the lexicon ...\n",
      "\t\treading the open class tags ...\n",
      "\tcalculating tag frequencies ...\n",
      "44000\tmaking affix tree ...\n",
      "prefix lexicon: 807 nodes\n",
      "suffix lexicon: 1796 nodes\n",
      "\treading classes ...\n",
      "\tmaking ngram table ...\n",
      "55427\t29913\n",
      "finished.\n",
      "\tmaking decision tree ...\n",
      "84\tsaving parameters ...\n",
      "\n",
      "Number of nodes: 85\n",
      "Max. path length: 14\n",
      "\n",
      "done.\n",
      "\treading parameters ...\n",
      "\ttagging ...\n",
      "7000\t finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 4/10 [00:17<00:25,  4.23s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train-tree-tagger -cl 2 -dtg 0.50 -sw 1.00 -ecw 0.15 -atg 1.20 lexicon.txt open_class.txt corpus_train.txt model_oc\n",
      "\n",
      "\treading the lexicon ...\n",
      "\t\treading the tagset ...\n",
      "\t\treading the lemmas ...\n",
      "\t\treading the entries ...\n",
      "\t\tsorting the lexicon ...\n",
      "\t\treading the open class tags ...\n",
      "\tcalculating tag frequencies ...\n",
      "44000\tmaking affix tree ...\n",
      "prefix lexicon: 807 nodes\n",
      "suffix lexicon: 1795 nodes\n",
      "\treading classes ...\n",
      "\tmaking ngram table ...\n",
      "55636\t29975\n",
      "finished.\n",
      "\tmaking decision tree ...\n",
      "92\tsaving parameters ...\n",
      "\n",
      "Number of nodes: 93\n",
      "Max. path length: 16\n",
      "\n",
      "done.\n",
      "\treading parameters ...\n",
      "\ttagging ...\n",
      "7000\t finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 5/10 [00:21<00:20,  4.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train-tree-tagger -cl 2 -dtg 0.50 -sw 1.00 -ecw 0.15 -atg 1.20 lexicon.txt open_class.txt corpus_train.txt model_oc\n",
      "\n",
      "\treading the lexicon ...\n",
      "\t\treading the tagset ...\n",
      "\t\treading the lemmas ...\n",
      "\t\treading the entries ...\n",
      "\t\tsorting the lexicon ...\n",
      "\t\treading the open class tags ...\n",
      "\tcalculating tag frequencies ...\n",
      "44000\tmaking affix tree ...\n",
      "prefix lexicon: 807 nodes\n",
      "suffix lexicon: 1797 nodes\n",
      "\treading classes ...\n",
      "\tmaking ngram table ...\n",
      "55677\t30386\n",
      "finished.\n",
      "\tmaking decision tree ...\n",
      "84\tsaving parameters ...\n",
      "\n",
      "Number of nodes: 85\n",
      "Max. path length: 15\n",
      "\n",
      "done.\n",
      "\treading parameters ...\n",
      "\ttagging ...\n",
      "7000\t finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 6/10 [00:24<00:16,  4.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train-tree-tagger -cl 2 -dtg 0.50 -sw 1.00 -ecw 0.15 -atg 1.20 lexicon.txt open_class.txt corpus_train.txt model_oc\n",
      "\n",
      "\treading the lexicon ...\n",
      "\t\treading the tagset ...\n",
      "\t\treading the lemmas ...\n",
      "\t\treading the entries ...\n",
      "\t\tsorting the lexicon ...\n",
      "\t\treading the open class tags ...\n",
      "\tcalculating tag frequencies ...\n",
      "46000\tmaking affix tree ...\n",
      "prefix lexicon: 807 nodes\n",
      "suffix lexicon: 1795 nodes\n",
      "\treading classes ...\n",
      "\tmaking ngram table ...\n",
      "57216\t31508\n",
      "finished.\n",
      "\tmaking decision tree ...\n",
      "70\tsaving parameters ...\n",
      "\n",
      "Number of nodes: 71\n",
      "Max. path length: 15\n",
      "\n",
      "done.\n",
      "\treading parameters ...\n",
      "\ttagging ...\n",
      "6000\t finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 7/10 [00:28<00:11,  3.84s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train-tree-tagger -cl 2 -dtg 0.50 -sw 1.00 -ecw 0.15 -atg 1.20 lexicon.txt open_class.txt corpus_train.txt model_oc\n",
      "\n",
      "\treading the lexicon ...\n",
      "\t\treading the tagset ...\n",
      "\t\treading the lemmas ...\n",
      "\t\treading the entries ...\n",
      "\t\tsorting the lexicon ...\n",
      "\t\treading the open class tags ...\n",
      "\tcalculating tag frequencies ...\n",
      "46000\tmaking affix tree ...\n",
      "prefix lexicon: 806 nodes\n",
      "suffix lexicon: 1795 nodes\n",
      "\treading classes ...\n",
      "\tmaking ngram table ...\n",
      "57336\t31217\n",
      "finished.\n",
      "\tmaking decision tree ...\n",
      "96\tsaving parameters ...\n",
      "\n",
      "Number of nodes: 97\n",
      "Max. path length: 15\n",
      "\n",
      "done.\n",
      "\treading parameters ...\n",
      "\ttagging ...\n",
      "5000\t finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 8/10 [00:32<00:08,  4.05s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train-tree-tagger -cl 2 -dtg 0.50 -sw 1.00 -ecw 0.15 -atg 1.20 lexicon.txt open_class.txt corpus_train.txt model_oc\n",
      "\n",
      "\treading the lexicon ...\n",
      "\t\treading the tagset ...\n",
      "\t\treading the lemmas ...\n",
      "\t\treading the entries ...\n",
      "\t\tsorting the lexicon ...\n",
      "\t\treading the open class tags ...\n",
      "\tcalculating tag frequencies ...\n",
      "47000\tmaking affix tree ...\n",
      "prefix lexicon: 807 nodes\n",
      "suffix lexicon: 1798 nodes\n",
      "\treading classes ...\n",
      "\tmaking ngram table ...\n",
      "58597\t31683\n",
      "finished.\n",
      "\tmaking decision tree ...\n",
      "82\tsaving parameters ...\n",
      "\n",
      "Number of nodes: 83\n",
      "Max. path length: 14\n",
      "\n",
      "done.\n",
      "\treading parameters ...\n",
      "\ttagging ...\n",
      "4000\t finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 9/10 [00:37<00:04,  4.17s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train-tree-tagger -cl 2 -dtg 0.50 -sw 1.00 -ecw 0.15 -atg 1.20 lexicon.txt open_class.txt corpus_train.txt model_oc\n",
      "\n",
      "\treading the lexicon ...\n",
      "\t\treading the tagset ...\n",
      "\t\treading the lemmas ...\n",
      "\t\treading the entries ...\n",
      "\t\tsorting the lexicon ...\n",
      "\t\treading the open class tags ...\n",
      "\tcalculating tag frequencies ...\n",
      "46000\tmaking affix tree ...\n",
      "prefix lexicon: 807 nodes\n",
      "suffix lexicon: 1799 nodes\n",
      "\treading classes ...\n",
      "\tmaking ngram table ...\n",
      "57621\t31148\n",
      "finished.\n",
      "\tmaking decision tree ...\n",
      "88\tsaving parameters ...\n",
      "\n",
      "Number of nodes: 89\n",
      "Max. path length: 14\n",
      "\n",
      "done.\n",
      "\treading parameters ...\n",
      "\ttagging ...\n",
      "5000\t finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 10/10 [00:41<00:00,  4.28s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(cross_val_folds))):\n",
    "    !rm corpus_train.txt\n",
    "    !rm corpus_test.txt\n",
    "    !rm output.txt\n",
    "    fd_train = open('corpus_train.txt', 'w')\n",
    "    fd_test = open('corpus_test.txt', 'w')\n",
    "    j = len(cross_val_folds) - 1\n",
    "    while j != -1:\n",
    "        if j == i:\n",
    "            for sent in cross_val_folds[i]:\n",
    "                fd_test.write('\\n' + '\\n'.join(sent[1].split()))\n",
    "        else:\n",
    "            for sent in cross_val_folds[j]:\n",
    "                fd_train.write(sent[0])\n",
    "        j -= 1\n",
    "    !./bin/train-tree-tagger lexicon.txt open_class.txt corpus_train.txt model_oc\n",
    "    !./bin/tree-tagger model_oc corpus_test.txt output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./bin/tree-tagger model_oc corpus_test.txt output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
